{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  Etapa 1 â€“ Escolha do Conjunto de Dados\n",
    "\n",
    "O dataset escolhido para este projeto foi retirado do Kaggle e trata de aspectos relacionados Ã  saÃºde e ao estilo de vida das pessoas.\n",
    "\n",
    "ðŸ”— **Fonte**: [Health and Lifestyle Dataset - Kaggle](https://www.kaggle.com/datasets/sahilislam007/health-and-lifestyle-dataset)\n",
    "\n",
    "Este dataset contÃ©m informaÃ§Ãµes como idade, altura, peso, frequÃªncia de exercÃ­cios, consumo de Ã¡lcool, tabagismo, entre outros aspectos importantes para anÃ¡lises preditivas relacionadas Ã  saÃºde.\n",
    "\n",
    "AlÃ©m disso, ele apresenta variÃ¡veis **numÃ©ricas e categÃ³ricas**, como solicitado na proposta da atividade.\n",
    "\n",
    "ðŸ‘‰ Dentre as etapas seguintes, o projeto contarÃ¡ com etapas de limpeza, EDA e modelagem preditiva a partir desse conjunto de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§¼ Etapa 2 â€“ Limpeza e PreparaÃ§Ã£o dos Dados\n",
    "\n",
    "Etapa para carregar o dataset, verificar valores ausentes, tratar inconsistÃªncias e aplicar tÃ©cnicas de preparaÃ§Ã£o para anÃ¡lise e modelagem.\n",
    "\n",
    "Foram utilizadas bibliotecas como `pandas`, `numpy` e `sklearn.preprocessing` para isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“¥ Importando bibliotecas necessÃ¡rias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# ConfiguraÃ§Ãµes visuais para grÃ¡ficos\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“‚ Carregando o dataset (ajuste o caminho conforme necessÃ¡rio)\n",
    "df = pd.read_csv(\"../data/health_and_lifestyle_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ” InformaÃ§Ãµes iniciais sobre os dados\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”Ž Verificando valores ausentes\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ¨ Preenchendo valores ausentes (exemplo genÃ©rico)\n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "\n",
    "# Se quiser apagar linhas com valores ausentes:\n",
    "# df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ§½ Removendo duplicatas (se existirem)\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”¢ Codificando variÃ¡veis categÃ³ricas\n",
    "label_enc = LabelEncoder()\n",
    "categorical_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "for col in categorical_cols:\n",
    "    df[col] = label_enc.fit_transform(df[col].astype(str))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š Normalizando os dados numÃ©ricos\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”Ž Etapa 3 â€“ AnÃ¡lise ExploratÃ³ria de Dados (EDA)\n",
    "\n",
    "Nesta etapa, serÃ£o analisadas estatÃ­sticas descritivas, criados grÃ¡ficos e identificados padrÃµes nos dados.\n",
    "\n",
    "O objetivo Ã© entender melhor o comportamento das variÃ¡veis e possÃ­veis relaÃ§Ãµes entre elas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“ˆ EstatÃ­sticas descritivas\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ” Verificando a correlaÃ§Ã£o entre variÃ¡veis numÃ©ricas\n",
    "correlation = df.corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation, annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Matriz de CorrelaÃ§Ã£o\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“Š DistribuiÃ§Ã£o de algumas variÃ¡veis\n",
    "df.hist(bins=20, figsize=(15, 10), color=\"skyblue\")\n",
    "plt.suptitle(\"DistribuiÃ§Ã£o das VariÃ¡veis NumÃ©ricas\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“¦ Boxplots para identificar outliers\n",
    "for col in df.select_dtypes(include=['float64', 'int64']).columns[:6]:\n",
    "    plt.figure()\n",
    "    sns.boxplot(data=df[col], color='lightcoral')\n",
    "    plt.title(f\"Boxplot de {col}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ¨ A partir desses grÃ¡ficos, Ã© possÃ­vel observar a distribuiÃ§Ã£o das variÃ¡veis, possÃ­veis outliers, e relaÃ§Ãµes entre os dados. Esses insights sÃ£o fundamentais para preparar a modelagem preditiva na prÃ³xima etapa!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤– Etapa 4 â€“ Modelagem Preditiva Simples\n",
    "\n",
    "Nesta etapa, um modelo de **classificaÃ§Ã£o** serÃ¡ treinado para prever um comportamento com base nas variÃ¡veis do dataset.\n",
    "\n",
    "SerÃ¡ utilizado o algoritmo **Random Forest Classifier**, pois ele Ã© robusto, fÃ¡cil de usar e funciona bem mesmo sem muitos ajustes. A mÃ©trica escolhida serÃ¡ o **F1-score**, ideal quando hÃ¡ classes desbalanceadas.\n",
    "\n",
    "âš ï¸ Nota: como o dataset original utilizado nÃ£o define uma variÃ¡vel alvo clara, vocÃª poderÃ¡ adaptar para prever, por exemplo, o hÃ¡bito de fumar (`Smoker`) ou IMC (`BMI`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m      8\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m2\u001b[39m  \u001b[38;5;66;03m# Frequente\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mExercise_Cat\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mExercise_Freq\u001b[39m\u001b[33m'\u001b[39m].apply(categorizar_exercicio)\n\u001b[32m     11\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mExercise_Cat\u001b[39m\u001b[33m'\u001b[39m].value_counts()\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# ðŸ”„ Convertendo a variÃ¡vel Exercise_Freq em categorias discretas\n",
    "def categorizar_exercicio(freq):\n",
    "    if freq <= 1:\n",
    "        return 0  # Nunca ou quase nunca\n",
    "    elif freq <= 3:\n",
    "        return 1  # Ã€s vezes\n",
    "    else:\n",
    "        return 2  # Frequente\n",
    "\n",
    "df['Exercise_Cat'] = df['Exercise_Freq'].apply(categorizar_exercicio)\n",
    "df['Exercise_Cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¯ Definindo nova variÃ¡vel alvo (categoria de exercÃ­cio) e features\n",
    "target = 'Exercise_Cat'\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ‚ï¸ Separando treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(\"Conjunto de treino:\", X_train.shape)\n",
    "print(\"Conjunto de teste:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŒ² Treinando o modelo Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ“ˆ Fazendo previsÃµes e avaliando\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"\\nRelatÃ³rio de ClassificaÃ§Ã£o:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ” Matriz de confusÃ£o\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "plt.title(\"Matriz de ConfusÃ£o\")\n",
    "plt.xlabel(\"Previsto\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœ… Modelo treinado e avaliado! Agora jÃ¡ temos uma base para entender os fatores que influenciam na variÃ¡vel `Exercise_Freq` (ou outra que vocÃª queira prever)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“Š Etapa 5 â€“ VisualizaÃ§Ã£o e RelatÃ³rio TÃ©cnico\n",
    "\n",
    "Etapa final em que serÃ£o exibidas as principais visualizaÃ§Ãµes e destacados os pontos mais relevantes que devem constar no relatÃ³rio final (`README.md`).\n",
    "\n",
    "Abaixo, as variÃ¡veis mais importantes para a prediÃ§Ã£o sÃ£o mostradas, com base no modelo Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŒŸ ImportÃ¢ncia das variÃ¡veis no modelo\n",
    "importances = model.feature_importances_\n",
    "features = X.columns\n",
    "importancia_df = pd.DataFrame({\"Feature\": features, \"ImportÃ¢ncia\": importances})\n",
    "importancia_df = importancia_df.sort_values(by=\"ImportÃ¢ncia\", ascending=False)\n",
    "\n",
    "sns.barplot(x=\"ImportÃ¢ncia\", y=\"Feature\", data=importancia_df.head(10), palette=\"viridis\")\n",
    "plt.title(\"Top 10 VariÃ¡veis mais Relevantes para a PrediÃ§Ã£o de ExercÃ­cio\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
