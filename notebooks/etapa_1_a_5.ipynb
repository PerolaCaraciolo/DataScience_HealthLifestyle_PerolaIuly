{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧠 Etapa 1 – Escolha do Conjunto de Dados\n",
    "\n",
    "O dataset escolhido para este projeto foi retirado do Kaggle e trata de aspectos relacionados à saúde e ao estilo de vida das pessoas.\n",
    "\n",
    "🔗 **Fonte**: [Health and Lifestyle Dataset - Kaggle](https://www.kaggle.com/datasets/sahilislam007/health-and-lifestyle-dataset)\n",
    "\n",
    "Este dataset contém informações como idade, altura, peso, frequência de exercícios, consumo de álcool, tabagismo, entre outros aspectos importantes para análises preditivas relacionadas à saúde.\n",
    "\n",
    "Além disso, ele apresenta variáveis **numéricas e categóricas**, como solicitado na proposta da atividade.\n",
    "\n",
    "👉 Dentre as etapas seguintes, o projeto contará com etapas de limpeza, EDA e modelagem preditiva a partir desse conjunto de dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧼 Etapa 2 – Limpeza e Preparação dos Dados\n",
    "\n",
    "Etapa para carregar o dataset, verificar valores ausentes, tratar inconsistências e aplicar técnicas de preparação para análise e modelagem.\n",
    "\n",
    "Foram utilizadas bibliotecas como `pandas`, `numpy` e `sklearn.preprocessing` para isso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📥 Importando bibliotecas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Configurações visuais para gráficos\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📂 Carregando o dataset (ajuste o caminho conforme necessário)\n",
    "df = pd.read_csv(\"../data/health_and_lifestyle_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 Informações iniciais sobre os dados\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔎 Verificando valores ausentes\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✨ Preenchendo valores ausentes (exemplo genérico)\n",
    "df.fillna(df.median(numeric_only=True), inplace=True)\n",
    "\n",
    "# Se quiser apagar linhas com valores ausentes:\n",
    "# df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🧽 Removendo duplicatas (se existirem)\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔢 Codificando variáveis categóricas\n",
    "label_enc = LabelEncoder()\n",
    "categorical_cols = df.select_dtypes(include=[\"object\"]).columns\n",
    "for col in categorical_cols:\n",
    "    df[col] = label_enc.fit_transform(df[col].astype(str))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Normalizando os dados numéricos\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔎 Etapa 3 – Análise Exploratória de Dados (EDA)\n",
    "\n",
    "Nesta etapa, serão analisadas estatísticas descritivas, criados gráficos e identificados padrões nos dados.\n",
    "\n",
    "O objetivo é entender melhor o comportamento das variáveis e possíveis relações entre elas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📈 Estatísticas descritivas\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 Verificando a correlação entre variáveis numéricas\n",
    "correlation = df.corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation, annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Matriz de Correlação\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📊 Distribuição de algumas variáveis\n",
    "df.hist(bins=20, figsize=(15, 10), color=\"skyblue\")\n",
    "plt.suptitle(\"Distribuição das Variáveis Numéricas\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 Boxplots para identificar outliers\n",
    "for col in df.select_dtypes(include=['float64', 'int64']).columns[:6]:\n",
    "    plt.figure()\n",
    "    sns.boxplot(data=df[col], color='lightcoral')\n",
    "    plt.title(f\"Boxplot de {col}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✨ A partir desses gráficos, é possível observar a distribuição das variáveis, possíveis outliers, e relações entre os dados. Esses insights são fundamentais para preparar a modelagem preditiva na próxima etapa!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🤖 Etapa 4 – Modelagem Preditiva Simples\n",
    "\n",
    "Nesta etapa, um modelo de **classificação** será treinado para prever um comportamento com base nas variáveis do dataset.\n",
    "\n",
    "Será utilizado o algoritmo **Random Forest Classifier**, pois ele é robusto, fácil de usar e funciona bem mesmo sem muitos ajustes. A métrica escolhida será o **F1-score**, ideal quando há classes desbalanceadas.\n",
    "\n",
    "⚠️ Nota: como o dataset original utilizado não define uma variável alvo clara, você poderá adaptar para prever, por exemplo, o hábito de fumar (`Smoker`) ou IMC (`BMI`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m      8\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m2\u001b[39m  \u001b[38;5;66;03m# Frequente\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mExercise_Cat\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mExercise_Freq\u001b[39m\u001b[33m'\u001b[39m].apply(categorizar_exercicio)\n\u001b[32m     11\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33mExercise_Cat\u001b[39m\u001b[33m'\u001b[39m].value_counts()\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "# 🔄 Convertendo a variável Exercise_Freq em categorias discretas\n",
    "def categorizar_exercicio(freq):\n",
    "    if freq <= 1:\n",
    "        return 0  # Nunca ou quase nunca\n",
    "    elif freq <= 3:\n",
    "        return 1  # Às vezes\n",
    "    else:\n",
    "        return 2  # Frequente\n",
    "\n",
    "df['Exercise_Cat'] = df['Exercise_Freq'].apply(categorizar_exercicio)\n",
    "df['Exercise_Cat'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🎯 Definindo nova variável alvo (categoria de exercício) e features\n",
    "target = 'Exercise_Cat'\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✂️ Separando treino e teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "print(\"Conjunto de treino:\", X_train.shape)\n",
    "print(\"Conjunto de teste:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🌲 Treinando o modelo Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📈 Fazendo previsões e avaliando\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"F1-score:\", f1_score(y_test, y_pred, average='weighted'))\n",
    "print(\"\\nRelatório de Classificação:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 Matriz de confusão\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"Blues\", fmt=\"d\")\n",
    "plt.title(\"Matriz de Confusão\")\n",
    "plt.xlabel(\"Previsto\")\n",
    "plt.ylabel(\"Real\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✅ Modelo treinado e avaliado! Agora já temos uma base para entender os fatores que influenciam na variável `Exercise_Freq` (ou outra que você queira prever)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📊 Etapa 5 – Visualização e Relatório Técnico\n",
    "\n",
    "Etapa final em que serão exibidas as principais visualizações e destacados os pontos mais relevantes que devem constar no relatório final (`README.md`).\n",
    "\n",
    "Abaixo, as variáveis mais importantes para a predição são mostradas, com base no modelo Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🌟 Importância das variáveis no modelo\n",
    "importances = model.feature_importances_\n",
    "features = X.columns\n",
    "importancia_df = pd.DataFrame({\"Feature\": features, \"Importância\": importances})\n",
    "importancia_df = importancia_df.sort_values(by=\"Importância\", ascending=False)\n",
    "\n",
    "sns.barplot(x=\"Importância\", y=\"Feature\", data=importancia_df.head(10), palette=\"viridis\")\n",
    "plt.title(\"Top 10 Variáveis mais Relevantes para a Predição de Exercício\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
